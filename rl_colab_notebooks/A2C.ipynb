{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "A2C.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8mkKaEyGGKT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "outputId": "7a17a2dd-a21e-4a5c-a73b-96c56a4cd235"
      },
      "source": [
        "!pip install box2d-py\n",
        "!pip install gym[Box_2D]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting box2d-py\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/06/bd/6cdc3fd994b0649dcf5d9bad85bd9e26172308bbe9a421bfc6fdbf5081a6/box2d_py-2.3.8-cp36-cp36m-manylinux1_x86_64.whl (448kB)\n",
            "\r\u001b[K     |▊                               | 10kB 18.3MB/s eta 0:00:01\r\u001b[K     |█▌                              | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |██▏                             | 30kB 2.4MB/s eta 0:00:01\r\u001b[K     |███                             | 40kB 1.7MB/s eta 0:00:01\r\u001b[K     |███▋                            | 51kB 1.9MB/s eta 0:00:01\r\u001b[K     |████▍                           | 61kB 2.3MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 71kB 2.5MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 81kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 92kB 3.0MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 102kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████                        | 112kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 122kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 133kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 143kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████                     | 153kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 163kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 174kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 184kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 194kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 204kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 215kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████                | 225kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 235kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 245kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 256kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 266kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 276kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 286kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 296kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 307kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 317kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 327kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 337kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 348kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 358kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 368kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 378kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 389kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 399kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 409kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 419kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 430kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 440kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 450kB 2.8MB/s \n",
            "\u001b[?25hInstalling collected packages: box2d-py\n",
            "Successfully installed box2d-py-2.3.8\n",
            "Requirement already satisfied: gym[Box_2D] in /usr/local/lib/python3.6/dist-packages (0.15.4)\n",
            "\u001b[33m  WARNING: gym 0.15.4 does not provide the extra 'box_2d'\u001b[0m\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from gym[Box_2D]) (4.1.2.30)\n",
            "Requirement already satisfied: six in /tensorflow-2.1.0/python3.6 (from gym[Box_2D]) (1.14.0)\n",
            "Requirement already satisfied: scipy in /tensorflow-2.1.0/python3.6 (from gym[Box_2D]) (1.4.1)\n",
            "Requirement already satisfied: pyglet<=1.3.2,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym[Box_2D]) (1.3.2)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /tensorflow-2.1.0/python3.6 (from gym[Box_2D]) (1.18.1)\n",
            "Requirement already satisfied: cloudpickle~=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym[Box_2D]) (1.2.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.3.2,>=1.2.0->gym[Box_2D]) (0.16.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lc0h9z2r8X_D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ae21ac22-9096-4c31-faa3-82fc6b52b50a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7IcJ0ezB7E6"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import numpy as np\n",
        "import gym\n",
        "import sys\n",
        "import tensorflow as tf \n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "tf.keras.backend.set_floatx('float64')\n",
        "actor_model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Dense(128,input_shape=(1,8),activation='relu'),\n",
        "  tf.keras.layers.Dense(4, activation='softmax')\n",
        "])\n",
        "actor_model.compile(loss='categorical_crossentropy',optimizer=tf.keras.optimizers.Adam(learning_rate = 0.001))\n",
        "\n",
        "critic_model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Dense(128,input_shape=(1,8),activation='relu'),\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "critic_model.compile(loss='mean_squared_error', optimizer=tf.keras.optimizers.Adam(learning_rate = 0.005))\n",
        "\n",
        "\n",
        "# actor_model.load_weights('/content/gdrive/My Drive/a2c/actor_model1000')\n",
        "# critic_model.load_weights('/content/gdrive/My Drive/a2c/critic_model1000')\n",
        " \n",
        "\n",
        "env = gym.make('LunarLander-v2')\n",
        "env.seed(1)\n",
        "env2 = gym.make('LunarLander-v2')\n",
        "env2.seed(2)\n",
        "episodes = 10000\n",
        "score=0\n",
        "episode_n=[]\n",
        "episode_n_test=[]\n",
        "score_train=[]\n",
        "score_test=[]\n",
        "\n",
        "\n",
        "def train2(previous_states,advantages,real_previous_values):\n",
        "    actor_model.train_on_batch(previous_states, advantages)\n",
        "    critic_model.train_on_batch(previous_states, real_previous_values)\n",
        "    \n",
        "def train(buff):\n",
        "    previous_states= []\n",
        "    real_previous_values=[]\n",
        "    advantages=[]\n",
        "\n",
        "    last_gae = 0.0\n",
        "    GAMMA = 0.99\n",
        "    GAE_LAMBDA = 0.95\n",
        "    for previous_state, action, reward, current_state, done in reversed(buff):\n",
        "        previous_states.append(previous_state)\n",
        "        if done:\n",
        "           delta = reward - critic_model(previous_state)\n",
        "           last_gae = delta\n",
        "        else:\n",
        "          delta = reward + GAMMA * critic_model(current_state) - critic_model(previous_state)\n",
        "          last_gae = delta + GAMMA * GAE_LAMBDA * last_gae\n",
        "        advantage=np.zeros((1,4))\n",
        "        advantage[0][action]=last_gae\n",
        "        advantages.append(advantage)\n",
        "        real_previous_values.append(last_gae + critic_model(previous_state))\n",
        " \n",
        "    previous_states=list(reversed(previous_states))\n",
        "    advantages=list(reversed(advantages))\n",
        "    real_previous_values=list(reversed(real_previous_values))\n",
        "    \n",
        "    previous_states=tf.convert_to_tensor(previous_states)\n",
        "\n",
        "    real_previous_values=tf.convert_to_tensor(real_previous_values)\n",
        "    advantages=tf.convert_to_tensor(advantages)\n",
        "\n",
        "    train2(previous_states,advantages,real_previous_values)\n",
        "\n",
        "def test():\n",
        "  score=0\n",
        "  for e in range(20):\n",
        "    state = env2.reset()\n",
        "    episode_score = 0\n",
        "    done = False\n",
        "    while not done:\n",
        "       state = state.reshape([1,8])\n",
        "       logits = actor_model(state)\n",
        "       a_dist = logits.numpy()\n",
        "       a = np.random.choice(a_dist[0],p=a_dist[0]) # Choose random action with p = action \n",
        "       a, = np.where(a_dist[0] == a)\n",
        "       a=a[0]\n",
        "       next_state, reward, done, _ = env2.step(a)\n",
        "       episode_score +=reward\n",
        "       state=next_state\n",
        "    score+=episode_score\n",
        "  return (score/20)\n",
        "\n",
        "for e in range(episodes):\n",
        "  state = env.reset()\n",
        "  episode_score = 0\n",
        "  episode_memory=[]\n",
        "  done = False\n",
        "  running_add=0\n",
        "  while not done:\n",
        "    state = state.reshape([1,8])\n",
        "    logits = actor_model(state)\n",
        "    a_dist = logits.numpy()\n",
        "    # env.render()\n",
        "    a = np.random.choice(a_dist[0],p=a_dist[0]) # Choose random action with p = action \n",
        "    a, = np.where(a_dist[0] == a)\n",
        "    a=a[0]\n",
        "    next_state, reward, done, _ = env.step(a)\n",
        "    next_state = next_state.reshape([1,8])\n",
        "    episode_score +=reward\n",
        "\n",
        "    # if done and not(episode_score==max_score):\n",
        "    # \trunning_add=-30\n",
        "\n",
        "    episode_memory.append([state, a, reward, next_state, done])\n",
        "    state=next_state\n",
        "  episode_memory=np.array(episode_memory)\n",
        "  train(episode_memory)\n",
        "  score+=episode_score\n",
        "  \n",
        "  episode_n.append(e+1)\n",
        "  print(\"Episode  {}  Score  {}\".format(e+1, episode_score))\n",
        "  score_train.append(episode_score)\n",
        "\n",
        "  if (e+1) % 10 == 0:\n",
        "    print(\"10 Episodes  mean train score  {}\".format(score/10))\n",
        "    score=0\n",
        "\n",
        "  if(e+1) % 500 == 0:\n",
        "    test_score=test()\n",
        "    episode_n_test.append(e+1)\n",
        "    score_test.append(test_score)\n",
        "\n",
        "    actor_model.save_weights('/content/gdrive/My Drive/a2c/actor_model'+str(e+1))\n",
        "    critic_model.save_weights('/content/gdrive/My Drive/a2c/critic_model'+str(e+1))\n",
        "    \n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(episode_n, score_train)\n",
        "ax.plot(episode_n_test, score_test)\n",
        "ax.set(xlabel='episode n', ylabel='score',title=':(')\n",
        "ax.grid()\n",
        "fig.legend(['Train score', 'Test score'], loc='upper left')\n",
        "fig.savefig(\"a2c_MC_gae.png\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}